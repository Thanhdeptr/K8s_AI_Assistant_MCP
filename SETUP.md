# üöÄ Setup Instructions

H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t v√† ch·∫°y K8s AI Assistant MCP Server v√† Backend Server.

## üìã Prerequisites

- Node.js 16+ (khuy·∫øn ngh·ªã Node.js 16.20.2)
- Kubernetes cluster v·ªõi kubectl ƒë√£ c·∫•u h√¨nh
- Ollama server (cho AI model)
- KUBECONFIG_PATH tr·ªè ƒë·∫øn file config c·ªßa cluster

## üîß C√†i ƒë·∫∑t

### 1. Clone Repository

```bash
git clone https://github.com/Thanhdeptr/K8s_AI_Assistant_MCP.git
cd K8s_AI_Assistant_MCP
```

### 2. C√†i ƒë·∫∑t Dependencies

```bash
# C√†i ƒë·∫∑t MCP Server
cd mcp-server-kubernetes
npm install
npm run build

# C√†i ƒë·∫∑t Backend Server (n·∫øu c√≥)
cd ../backend-server
npm install
```

## üöÄ Ch·∫°y MCP Server

### C√°ch 1: Ch·∫°y tr·ª±c ti·∫øp

```bash
cd mcp-server-kubernetes/dist

# Ch·∫°y v·ªõi c·∫•u h√¨nh c∆° b·∫£n
KUBECONFIG_PATH=/home/hatthanh/.kube/config \
ENABLE_UNSAFE_SSE_TRANSPORT=true \
HOST=0.0.0.0 \
node index.js
```

### C√°ch 2: Ch·∫°y v·ªõi script

```bash
# T·∫°o script ch·∫°y
cat > run-mcp-server.sh << 'EOF'
#!/bin/bash
export KUBECONFIG_PATH=/home/hatthanh/.kube/config
export ENABLE_UNSAFE_SSE_TRANSPORT=true
export HOST=0.0.0.0

cd mcp-server-kubernetes/dist
node index.js
EOF

chmod +x run-mcp-server.sh
./run-mcp-server.sh
```

### Output mong ƒë·ª£i:

```
SSE server started
‚úÖ MCP-kubernetes-server is listening on port 3000
‚ùì Use the following url to connect to the server:
   http://0.0.0.0:3000/sse
‚ùì Resume: http://0.0.0.0:3000/sse?sessionId=<existing-session-id>
‚ôæÔ∏è Sessions never expire - manual reconnect required when disconnected
```

## üåê Ch·∫°y Backend Server

### C√°ch ch·∫°y Backend Server:

```bash
cd backend-server
node server.js
```

### Output mong ƒë·ª£i:

```
API ch·∫°y: http://0.0.0.0:8055
Ollama baseURL: http://192.168.10.32:11434/v1 | MODEL: gpt-oss:20b
MCP base: http://192.168.10.18:3000 (HTTP + SSE)

Flow: GET /sse - nh·∫≠n "event: endpoint" -> POST JSON-RPC v√†o /messages?sessionId=...
connect() called sessionPath: null, connectionState: disconnected, sessionId: null
Creating new MCP SSE connection to: http://192.168.10.18:3000
Extracted session ID: 5d8d61f7-0587-4e8a-95f8-75e7d7691ce0

MCP RPC (attempt 1): initialize to http://192.168.10.18:3000/messages?sessionId=5d8d61f7-0587-4e8a-95f8-75e7d7691ce0
About to send POST to: http://192.168.10.18:3000/messages?sessionId=5d8d61f7-0587-4e8a-95f8-75e7d7691ce0
POST response status: 202
MCP RPC sent successfully, waiting for SSE response...

MCP session endpoint: /messages?sessionId=5d8d61f7-0587-4e8a-95f8-75e7d7691ce0

Loaded Tools from MCP:
- 'cleanup'
- 'kubectl_describe'
- 'kubectl_delete'
- 'kubectl_logs'
- 'kubectl_patch'
- 'kubectl_context'
- 'kubectl_get'
- 'kubectl_apply'
- 'kubectl_create'
- 'kubectl_scale'
- 'kubectl_rollout'
- 'explain_resource'
- 'install_helm_chart'
- 'upgrade_helm_chart'
- 'uninstall_helm_chart'
- 'port_forward'
- 'stop_port_forward'
- 'exec_in_pod'
- 'list_api_resources'
- 'kubectl_generic'
- 'ping'
```

## ‚öôÔ∏è C·∫•u h√¨nh

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `KUBECONFIG_PATH` | ƒê∆∞·ªùng d·∫´n ƒë·∫øn file kubeconfig | `/home/hatthanh/.kube/config` |
| `ENABLE_UNSAFE_SSE_TRANSPORT` | B·∫≠t SSE transport | `true` |
| `HOST` | Host ƒë·ªÉ bind server | `0.0.0.0` |
| `PORT` | Port cho MCP server | `3000` |
| `OLLAMA_BASE_URL` | URL c·ªßa Ollama server | `http://192.168.10.32:11434/v1` |
| `OLLAMA_MODEL` | Model AI s·ª≠ d·ª•ng | `gpt-oss:20b` |

### C·∫•u h√¨nh Ollama

1. **C√†i ƒë·∫∑t Ollama:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

2. **Pull model:**
```bash
ollama pull gpt-oss:20b
```

3. **Ch·∫°y Ollama server:**
```bash
ollama serve
```

## üîó K·∫øt n·ªëi

### MCP Server Endpoints

- **SSE Endpoint:** `http://0.0.0.0:3000/sse`
- **Resume Session:** `http://0.0.0.0:3000/sse?sessionId=<session-id>`

### Backend Server Endpoints

- **API Base:** `http://0.0.0.0:8055`
- **MCP Connection:** `http://192.168.10.18:3000`

## üõ†Ô∏è Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p:

1. **KUBECONFIG_PATH kh√¥ng t√¨m th·∫•y:**
```bash
export KUBECONFIG_PATH=/path/to/your/kubeconfig
```

2. **Ollama server kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c:**
```bash
# Ki·ªÉm tra Ollama ƒëang ch·∫°y
curl http://192.168.10.32:11434/v1/models

# Restart Ollama n·∫øu c·∫ßn
sudo systemctl restart ollama
```

3. **Port ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng:**
```bash
# Ki·ªÉm tra port ƒëang s·ª≠ d·ª•ng
netstat -tulpn | grep :3000

# Kill process n·∫øu c·∫ßn
kill -9 <PID>
```

4. **MCP connection failed:**
```bash
# Ki·ªÉm tra MCP server ƒëang ch·∫°y
curl http://0.0.0.0:3000/sse

# Restart MCP server
pkill -f "node index.js"
```

## üìù Logs

### MCP Server Logs
```bash
# Xem logs real-time
tail -f mcp-server-kubernetes/logs/mcp-server.log

# Xem logs v·ªõi timestamp
journalctl -u mcp-server -f
```

### Backend Server Logs
```bash
# Xem logs real-time
tail -f backend-server/logs/server.log

# Xem logs v·ªõi timestamp
journalctl -u backend-server -f
```

## üîÑ Auto-restart v·ªõi PM2

### C√†i ƒë·∫∑t PM2:
```bash
npm install -g pm2
```

### T·∫°o PM2 config:
```bash
cat > ecosystem.config.js << 'EOF'
module.exports = {
  apps: [
    {
      name: 'mcp-server',
      script: 'mcp-server-kubernetes/dist/index.js',
      cwd: './',
      env: {
        KUBECONFIG_PATH: '/home/hatthanh/.kube/config',
        ENABLE_UNSAFE_SSE_TRANSPORT: 'true',
        HOST: '0.0.0.0',
        PORT: '3000'
      },
      instances: 1,
      autorestart: true,
      watch: false,
      max_memory_restart: '1G'
    },
    {
      name: 'backend-server',
      script: 'backend-server/server.js',
      cwd: './',
      env: {
        PORT: '8055',
        OLLAMA_BASE_URL: 'http://192.168.10.32:11434/v1',
        OLLAMA_MODEL: 'gpt-oss:20b'
      },
      instances: 1,
      autorestart: true,
      watch: false,
      max_memory_restart: '1G'
    }
  ]
};
EOF
```

### Ch·∫°y v·ªõi PM2:
```bash
# Start t·∫•t c·∫£ services
pm2 start ecosystem.config.js

# Xem status
pm2 status

# Xem logs
pm2 logs

# Restart services
pm2 restart all

# Stop services
pm2 stop all
```

## ‚úÖ Ki·ªÉm tra ho·∫°t ƒë·ªông

### Test MCP Server:
```bash
# Test SSE connection
curl http://0.0.0.0:3000/sse

# Test kubectl tools
curl -X POST http://0.0.0.0:3000/messages \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc": "2.0", "method": "tools/list", "id": 1}'
```

### Test Backend Server:
```bash
# Test API health
curl http://0.0.0.0:8055/health

# Test Ollama connection
curl http://0.0.0.0:8055/api/ollama/status
```

---

**üéØ L∆∞u √Ω:** ƒê·∫£m b·∫£o t·∫•t c·∫£ services (Ollama, MCP Server, Backend Server) ƒë·ªÅu ƒëang ch·∫°y tr∆∞·ªõc khi s·ª≠ d·ª•ng K8s AI Assistant!