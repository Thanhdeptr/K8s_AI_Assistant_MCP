# üöÄ Setup Instructions

H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t v√† ch·∫°y K8s AI Assistant MCP Server v√† Backend Server.

## üìã Prerequisites

- Node.js 16+ (khuy·∫øn ngh·ªã Node.js 16.20.2)
- Kubernetes cluster v·ªõi kubectl ƒë√£ c·∫•u h√¨nh
- Ollama server (cho AI model)
- KUBECONFIG_PATH tr·ªè ƒë·∫øn file config c·ªßa cluster
- Yarn package manager

## üîß C√†i ƒë·∫∑t

### 1. Clone Repository

```bash
git clone https://github.com/Thanhdeptr/K8s_AI_Assistant_MCP.git
cd K8s_AI_Assistant_MCP
```

### 2. C√†i ƒë·∫∑t Dependencies

```bash
# C√†i ƒë·∫∑t MCP Server
cd mcp-server-kubernetes
npm install
npm run build

# C√†i ƒë·∫∑t Backend Server (n·∫øu c√≥)
cd ../backend-server
npm install

# C√†i ƒë·∫∑t Frontend Extensions
cd ../rancher-ui
yarn install
```

## üöÄ Ch·∫°y MCP Server

### C√°ch 1: Ch·∫°y tr·ª±c ti·∫øp

```bash
cd mcp-server-kubernetes/dist

# Ch·∫°y v·ªõi c·∫•u h√¨nh c∆° b·∫£n
KUBECONFIG_PATH=/home/hatthanh/.kube/config \
ENABLE_UNSAFE_SSE_TRANSPORT=true \
HOST=0.0.0.0 \
node index.js
```

### C√°ch 2: Ch·∫°y v·ªõi script

```bash
# T·∫°o script ch·∫°y
cat > run-mcp-server.sh << 'EOF'
#!/bin/bash
export KUBECONFIG_PATH=/home/hatthanh/.kube/config
export ENABLE_UNSAFE_SSE_TRANSPORT=true
export HOST=0.0.0.0

cd mcp-server-kubernetes/dist
node index.js
EOF

chmod +x run-mcp-server.sh
./run-mcp-server.sh
```

### Output mong ƒë·ª£i:

```
SSE server started
‚úÖ MCP-kubernetes-server is listening on port 3000
‚ùì Use the following url to connect to the server:
   http://0.0.0.0:3000/sse
‚ùì Resume: http://0.0.0.0:3000/sse?sessionId=<existing-session-id>
‚ôæÔ∏è Sessions never expire - manual reconnect required when disconnected
```

## üåê Ch·∫°y Backend Server

### C√°ch ch·∫°y Backend Server:

```bash
cd backend-server
node server.js
```

### Output mong ƒë·ª£i:

```
API ch·∫°y: http://0.0.0.0:8055
Ollama baseURL: http://192.168.10.32:11434/v1 | MODEL: gpt-oss:20b
MCP base: http://192.168.10.18:3000 (HTTP + SSE)

Flow: GET /sse - nh·∫≠n "event: endpoint" -> POST JSON-RPC v√†o /messages?sessionId=...
connect() called sessionPath: null, connectionState: disconnected, sessionId: null
Creating new MCP SSE connection to: http://192.168.10.18:3000
Extracted session ID: 5d8d61f7-0587-4e8a-95f8-75e7d7691ce0

MCP RPC (attempt 1): initialize to http://192.168.10.18:3000/messages?sessionId=5d8d61f7-0587-4e8a-95f8-75e7d7691ce0
About to send POST to: http://192.168.10.18:3000/messages?sessionId=5d8d61f7-0587-4e8a-95f8-75e7d7691ce0
POST response status: 202
MCP RPC sent successfully, waiting for SSE response...

MCP session endpoint: /messages?sessionId=5d8d61f7-0587-4e8a-95f8-75e7d7691ce0

Loaded Tools from MCP:
- 'cleanup'
- 'kubectl_describe'
- 'kubectl_delete'
- 'kubectl_logs'
- 'kubectl_patch'
- 'kubectl_context'
- 'kubectl_get'
- 'kubectl_apply'
- 'kubectl_create'
- 'kubectl_scale'
- 'kubectl_rollout'
- 'explain_resource'
- 'install_helm_chart'
- 'upgrade_helm_chart'
- 'uninstall_helm_chart'
- 'port_forward'
- 'stop_port_forward'
- 'exec_in_pod'
- 'list_api_resources'
- 'kubectl_generic'
- 'ping'
```

## üé® Ch·∫°y Frontend Extensions (Rancher UI)

### Build v√† ch·∫°y extensions locally:

```bash
cd rancher-ui

# 1. C√†i ƒë·∫∑t dependencies
yarn install

# 2. Set API environment variable ƒë·ªÉ tr·ªè ƒë·∫øn Rancher backend
export API=https://192.168.10.18:8005

# 3. Ch·∫°y Rancher trong development mode
yarn dev
```

### Truy c·∫≠p Rancher UI:

1. **M·ªü web browser** v√† truy c·∫≠p: `https://192.168.10.18:8005`
2. **ƒêƒÉng nh·∫≠p** v√†o Rancher
3. **Extensions s·∫Ω t·ª± ƒë·ªông load** sau khi ƒëƒÉng nh·∫≠p
4. **Hot-reload** s·∫Ω ho·∫°t ƒë·ªông khi edit code

### Output mong ƒë·ª£i:

```
yarn run v1.22.19
$ webpack serve --config webpack.config.js
‚Ñπ ÔΩ¢wdsÔΩ£: Project is running at https://192.168.10.18:8005/
‚Ñπ ÔΩ¢wdsÔΩ£: webpack output is served from /
‚Ñπ ÔΩ¢wdsÔΩ£: Content not from webpack is served from /path/to/rancher-ui
‚Ñπ ÔΩ¢wdsÔΩ£: 404s will fallback to /index.html
```

### Development Workflow:

```bash
# 1. Start development server
yarn dev

# 2. Edit extension code trong src/ directory
# 3. Changes s·∫Ω t·ª± ƒë·ªông reload trong browser
# 4. Check browser console cho errors

# 5. Build for production
yarn build

# 6. Package extensions
yarn package
```

## ‚öôÔ∏è C·∫•u h√¨nh

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `KUBECONFIG_PATH` | ƒê∆∞·ªùng d·∫´n ƒë·∫øn file kubeconfig | `/home/hatthanh/.kube/config` |
| `ENABLE_UNSAFE_SSE_TRANSPORT` | B·∫≠t SSE transport | `true` |
| `HOST` | Host ƒë·ªÉ bind server | `0.0.0.0` |
| `PORT` | Port cho MCP server | `3000` |
| `OLLAMA_BASE_URL` | URL c·ªßa Ollama server | `http://192.168.10.32:11434/v1` |
| `OLLAMA_MODEL` | Model AI s·ª≠ d·ª•ng | `gpt-oss:20b` |
| `API` | Rancher backend URL | `https://192.168.10.18:8005` |

### C·∫•u h√¨nh Ollama

1. **C√†i ƒë·∫∑t Ollama:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

2. **Pull model:**
```bash
ollama pull gpt-oss:20b
```

3. **Ch·∫°y Ollama server:**
```bash
ollama serve
```

## üîó K·∫øt n·ªëi

### MCP Server Endpoints

- **SSE Endpoint:** `http://0.0.0.0:3000/sse`
- **Resume Session:** `http://0.0.0.0:3000/sse?sessionId=<session-id>`

### Backend Server Endpoints

- **API Base:** `http://0.0.0.0:8055`
- **MCP Connection:** `http://192.168.10.18:3000`

### Frontend Extensions

- **Rancher UI:** `https://192.168.10.18:8005`
- **Development Server:** `https://192.168.10.18:8005`

## üõ†Ô∏è Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p:

1. **KUBECONFIG_PATH kh√¥ng t√¨m th·∫•y:**
```bash
export KUBECONFIG_PATH=/path/to/your/kubeconfig
```

2. **Ollama server kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c:**
```bash
# Ki·ªÉm tra Ollama ƒëang ch·∫°y
curl http://192.168.10.32:11434/v1/models

# Restart Ollama n·∫øu c·∫ßn
sudo systemctl restart ollama
```

3. **Port ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng:**
```bash
# Ki·ªÉm tra port ƒëang s·ª≠ d·ª•ng
netstat -tulpn | grep :3000

# Kill process n·∫øu c·∫ßn
kill -9 <PID>
```

4. **MCP connection failed:**
```bash
# Ki·ªÉm tra MCP server ƒëang ch·∫°y
curl http://0.0.0.0:3000/sse

# Restart MCP server
pkill -f "node index.js"
```

5. **Frontend extensions kh√¥ng load:**
```bash
# Ki·ªÉm tra API environment variable
echo $API

# Restart development server
pkill -f "yarn dev"
yarn dev
```

6. **SSL certificate issues:**
```bash
# B·ªè qua SSL verification cho development
export NODE_TLS_REJECT_UNAUTHORIZED=0
```

## üìù Logs

### MCP Server Logs
```bash
# Xem logs real-time
tail -f mcp-server-kubernetes/logs/mcp-server.log

# Xem logs v·ªõi timestamp
journalctl -u mcp-server -f
```

### Backend Server Logs
```bash
# Xem logs real-time
tail -f backend-server/logs/server.log

# Xem logs v·ªõi timestamp
journalctl -u backend-server -f
```

### Frontend Development Logs
```bash
# Xem webpack dev server logs
tail -f rancher-ui/webpack.log

# Browser console logs (F12 trong browser)
```

## üîÑ Auto-restart v·ªõi PM2

### C√†i ƒë·∫∑t PM2:
```bash
npm install -g pm2
```

### T·∫°o PM2 config:
```bash
cat > ecosystem.config.js << 'EOF'
module.exports = {
  apps: [
    {
      name: 'mcp-server',
      script: 'mcp-server-kubernetes/dist/index.js',
      cwd: './',
      env: {
        KUBECONFIG_PATH: '/home/hatthanh/.kube/config',
        ENABLE_UNSAFE_SSE_TRANSPORT: 'true',
        HOST: '0.0.0.0',
        PORT: '3000'
      },
      instances: 1,
      autorestart: true,
      watch: false,
      max_memory_restart: '1G'
    },
    {
      name: 'backend-server',
      script: 'backend-server/server.js',
      cwd: './',
      env: {
        PORT: '8055',
        OLLAMA_BASE_URL: 'http://192.168.10.32:11434/v1',
        OLLAMA_MODEL: 'gpt-oss:20b'
      },
      instances: 1,
      autorestart: true,
      watch: false,
      max_memory_restart: '1G'
    },
    {
      name: 'frontend-dev',
      script: 'yarn',
      args: 'dev',
      cwd: './rancher-ui',
      env: {
        API: 'https://192.168.10.18:8005'
      },
      instances: 1,
      autorestart: true,
      watch: false,
      max_memory_restart: '1G'
    }
  ]
};
EOF
```

### Ch·∫°y v·ªõi PM2:
```bash
# Start t·∫•t c·∫£ services
pm2 start ecosystem.config.js

# Xem status
pm2 status

# Xem logs
pm2 logs

# Restart services
pm2 restart all

# Stop services
pm2 stop all
```

## ‚úÖ Ki·ªÉm tra ho·∫°t ƒë·ªông

### Test MCP Server:
```bash
# Test SSE connection
curl http://0.0.0.0:3000/sse

# Test kubectl tools
curl -X POST http://0.0.0.0:3000/messages \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc": "2.0", "method": "tools/list", "id": 1}'
```

### Test Backend Server:
```bash
# Test API health
curl http://0.0.0.0:8055/health

# Test Ollama connection
curl http://0.0.0.0:8055/api/ollama/status
```

### Test Frontend Extensions:
```bash
# Ki·ªÉm tra development server
curl -k https://192.168.10.18:8005

# Ki·ªÉm tra extensions loaded
# M·ªü browser v√† check console logs
```

## üöÄ Quick Start Script

T·∫°o script ƒë·ªÉ ch·∫°y t·∫•t c·∫£ services c√πng l√∫c:

```bash
cat > start-all.sh << 'EOF'
#!/bin/bash

echo "üöÄ Starting K8s AI Assistant MCP..."

# Set environment variables
export KUBECONFIG_PATH=/home/hatthanh/.kube/config
export ENABLE_UNSAFE_SSE_TRANSPORT=true
export HOST=0.0.0.0
export API=https://192.168.10.18:8005

# Start MCP Server
echo "üì° Starting MCP Server..."
cd mcp-server-kubernetes/dist
node index.js &
MCP_PID=$!

# Start Backend Server
echo "üîß Starting Backend Server..."
cd ../../backend-server
node server.js &
BACKEND_PID=$!

# Start Frontend Development
echo "üé® Starting Frontend Extensions..."
cd ../rancher-ui
yarn dev &
FRONTEND_PID=$!

echo "‚úÖ All services started!"
echo "MCP Server PID: $MCP_PID"
echo "Backend Server PID: $BACKEND_PID"
echo "Frontend PID: $FRONTEND_PID"
echo ""
echo "üåê Access points:"
echo "  - Rancher UI: https://192.168.10.18:8005"
echo "  - MCP Server: http://0.0.0.0:3000/sse"
echo "  - Backend API: http://0.0.0.0:8055"
echo ""
echo "Press Ctrl+C to stop all services"

# Wait for interrupt
trap "echo 'üõë Stopping all services...'; kill $MCP_PID $BACKEND_PID $FRONTEND_PID; exit" INT
wait
EOF

chmod +x start-all.sh
./start-all.sh
```

---

**üéØ L∆∞u √Ω:** ƒê·∫£m b·∫£o t·∫•t c·∫£ services (Ollama, MCP Server, Backend Server, Frontend Extensions) ƒë·ªÅu ƒëang ch·∫°y tr∆∞·ªõc khi s·ª≠ d·ª•ng K8s AI Assistant!